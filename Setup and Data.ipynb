{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51da16d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import pycountry\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1861ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad971c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "main_df = pd.read_excel(\"Data/organizedviolencecy_v23_2.xlsx\")\n",
    "\n",
    "# List of country codes to keep (recognized country)\n",
    "recognized_country_codes = [\n",
    "    \"AFG\", \"ALA\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"AIA\", \"ATA\", \"ATG\", \"ARG\", \"ARM\", \"ABW\", \"AUS\", \"AUT\", \"AZE\",\n",
    "    \"BHS\", \"BHR\", \"BGD\", \"BRB\", \"BLR\", \"BEL\", \"BLZ\", \"BEN\", \"BMU\", \"BTN\", \"BOL\", \"BES\", \"BIH\", \"BWA\", \"BVT\", \"BRA\",\n",
    "    \"IOT\", \"BRN\", \"BGR\", \"BFA\", \"BDI\", \"CPV\", \"KHM\", \"CMR\", \"CAN\", \"CYM\", \"CAF\", \"TCD\", \"CHL\", \"CHN\", \"CXR\", \"CCK\",\n",
    "    \"COL\", \"COM\", \"COG\", \"COD\", \"COK\", \"CRI\", \"CIV\", \"HRV\", \"CUB\", \"CUW\", \"CYP\", \"CZE\", \"DNK\", \"DJI\", \"DMA\", \"DOM\",\n",
    "    \"ECU\", \"EGY\", \"SLV\", \"GNQ\", \"ERI\", \"EST\", \"SWZ\", \"ETH\", \"FLK\", \"FRO\", \"FJI\", \"FIN\", \"FRA\", \"GUF\", \"PYF\", \"ATF\",\n",
    "    \"GAB\", \"GMB\", \"GEO\", \"DEU\", \"GHA\", \"GIB\", \"GRC\", \"GRL\", \"GRD\", \"GLP\", \"GUM\", \"GTM\", \"GGY\", \"GIN\", \"GNB\", \"GUY\",\n",
    "    \"HTI\", \"HMD\", \"VAT\", \"HND\", \"HKG\", \"HUN\", \"ISL\", \"IND\", \"IDN\", \"IRN\", \"IRQ\", \"IRL\", \"IMN\", \"ISR\", \"ITA\", \"JAM\",\n",
    "    \"JPN\", \"JEY\", \"JOR\", \"KAZ\", \"KEN\", \"KIR\", \"PRK\", \"KOR\", \"KWT\", \"KGZ\", \"LAO\", \"LVA\", \"LBN\", \"LSO\", \"LBR\", \"LBY\",\n",
    "    \"LIE\", \"LTU\", \"LUX\", \"MAC\", \"MDG\", \"MWI\", \"MYS\", \"MDV\", \"MLI\", \"MLT\", \"MHL\", \"MTQ\", \"MRT\", \"MUS\", \"MYT\", \"MEX\",\n",
    "    \"FSM\", \"MDA\", \"MCO\", \"MNG\", \"MNE\", \"MSR\", \"MAR\", \"MOZ\", \"MMR\", \"NAM\", \"NRU\", \"NPL\", \"NLD\", \"NCL\", \"NZL\", \"NIC\",\n",
    "    \"NER\", \"NGA\", \"NIU\", \"NFK\", \"MKD\", \"MNP\", \"NOR\", \"OMN\", \"PAK\", \"PLW\", \"PSE\", \"PAN\", \"PNG\", \"PRY\", \"PER\", \"PHL\",\n",
    "    \"PCN\", \"POL\", \"PRT\", \"PRI\", \"QAT\", \"REU\", \"ROU\", \"RUS\", \"RWA\", \"BLM\", \"SHN\", \"KNA\", \"LCA\", \"MAF\", \"SPM\", \"VCT\",\n",
    "    \"WSM\", \"SMR\", \"STP\", \"SAU\", \"SEN\", \"SRB\", \"SYC\", \"SLE\", \"SGP\", \"SXM\", \"SVK\", \"SVN\", \"SLB\", \"SOM\", \"ZAF\", \"SGS\",\n",
    "    \"SSD\", \"ESP\", \"LKA\", \"SDN\", \"SUR\", \"SJM\", \"SWE\", \"CHE\", \"SYR\", \"TWN\", \"TJK\", \"TZA\", \"THA\", \"TLS\", \"TGO\", \"TKL\",\n",
    "    \"TON\", \"TTO\", \"TUN\", \"TUR\", \"TKM\", \"TCA\", \"TUV\", \"UGA\", \"UKR\", \"ARE\", \"GBR\", \"USA\", \"UMI\", \"URY\", \"UZB\", \"VUT\",\n",
    "    \"VEN\", \"VNM\", \"VGB\", \"VIR\", \"WLF\", \"ESH\", \"YEM\", \"ZMB\", \"ZWE\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfed3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create dictionaries to map country names to ISO codes and vice versa\n",
    "country_name_to_iso = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "iso_to_country_name = {country.alpha_3: country.name for country in pycountry.countries}\n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "df_country_name_to_iso = pd.DataFrame(list(country_name_to_iso.items()), columns=['Country Name', 'ISO_Code'])\n",
    "df_iso_to_country_name = pd.DataFrame(list(iso_to_country_name.items()), columns=['ISO_Code', 'Country Name'])\n",
    "\n",
    "# Merge the DataFrames into a single DataFrame without duplicating \"Country Name\"\n",
    "iso_df = pd.merge(df_country_name_to_iso, df_iso_to_country_name, on='ISO_Code', how='inner', suffixes=('_country', '_iso'))\n",
    "\n",
    "# Rename the \"Country Name\" column to \"Name\"\n",
    "iso_df.rename(columns={'Country Name_country': 'Name', 'ISO_Code': 'stateid'}, inplace=True)\n",
    "\n",
    "# Drop the duplicate \"Country Name_iso\" column\n",
    "iso_df.drop(columns=['Country Name_iso'], inplace=True)\n",
    "\n",
    "# Only keep the countries in the recognized_country_codes list\n",
    "iso_df = iso_df[iso_df['stateid'].isin(recognized_country_codes)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3ed6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stateids are not consistent for the following countries:\n",
      "['Congo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/yj7hjzq14d1665_z13gnp8980000gn/T/ipykernel_90219/2016274278.py:16: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  gdp_df = gdp_df.fillna(method='bfill', axis=1)\n",
      "/var/folders/66/yj7hjzq14d1665_z13gnp8980000gn/T/ipykernel_90219/2016274278.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  gdp_df = gdp_df.fillna(method='ffill', axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning of GDP dataset: GDP between 1989 and 2022 in current US dollars\n",
    "gdp_df = pd.read_csv(\"Data/gdp_world.csv\", skiprows=4)\n",
    "\n",
    "# Only keep Country Code is in recognized_country_codes\n",
    "gdp_df = gdp_df[gdp_df[\"Country Code\"].isin(recognized_country_codes)]\n",
    "\n",
    "# Only keep relevant columns\n",
    "gdp_df = gdp_df[[\"Country Name\", \"Country Code\", \"1989\", \"1990\", \"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\",\n",
    "                 \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\",\n",
    "                 \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]]\n",
    "\n",
    "# Only keep the countries recognized in the recognized_country_codes list\n",
    "gdp_df = gdp_df[gdp_df[\"Country Code\"].isin(recognized_country_codes)]\n",
    "\n",
    "# Backfill NaN values\n",
    "gdp_df = gdp_df.fillna(method='bfill', axis=1)\n",
    "\n",
    "# rename Country Code to stateid\n",
    "gdp_df = gdp_df.rename(columns={\"Country Code\": \"stateid\"})\n",
    "\n",
    "# Frontfill NaN values -> some countries miss their 2022 value\n",
    "gdp_df = gdp_df.fillna(method='ffill', axis=1)\n",
    "\n",
    "\n",
    "# Initialize the mapping dictionary\n",
    "name_mapping = {\n",
    "    \"Congo, Dem. Rep.\": \"Congo\",\n",
    "    \"Tanzania\": \"Tanzania, United Republic of\",\n",
    "    \"Turkiye\": \"Türkiye\",\n",
    "    \"Moldova\": \"Moldova, Republic of\",\n",
    "    \"Bahamas, The\": \"Bahamas\",\n",
    "    \"Macao SAR, China\": \"China\",\n",
    "    \"Korea, Rep.\": \"Korea, Republic of\",\n",
    "    \"Curacao\": \"Curaçao\",\n",
    "    \"Egypt, Arab Rep.\": \"Egypt\",\n",
    "    \"Congo, Rep.\": \"Congo\",\n",
    "    \"Bolivia\": \"Bolivia, Plurinational State of\",\n",
    "    \"Virgin Islands (U.S.)\": \"Virgin Islands, U.S.\",\n",
    "    \"St. Vincent and the Grenadines\": \"Saint Vincent and the Grenadines\",\n",
    "    \"St. Martin (French part)\": \"Saint Martin (French part)\",\n",
    "    \"Hong Kong SAR, China\": \"Hong Kong\",\n",
    "    \"British Virgin Islands\": \"Virgin Islands, British\",\n",
    "    \"Yemen, Rep.\": \"Yemen\",\n",
    "    \"Cote d'Ivoire\": \"Côte d'Ivoire\",\n",
    "    \"St. Kitts and Nevis\": \"Saint Kitts and Nevis\",\n",
    "    \"Gambia, The\": \"Gambia\",\n",
    "    # Add mappings for the countries not found in the ISO dataset\n",
    "    \"Micronesia, Fed. Sts.\": \"\",  # Change this to the correct ISO name\n",
    "    \"Lao PDR\": \"\",  # Change this to the correct ISO name\n",
    "    \"Iran, Islamic Rep.\": \"\",  # Change this to the correct ISO name\n",
    "    \"Korea, Dem. People's Rep.\": \"\",  # Change this to the correct ISO name\n",
    "    \"Kyrgyz Republic\": \"\",  # Change this to the correct ISO name\n",
    "    \"St. Lucia\": \"\",  # Change this to the correct ISO name\n",
    "    \"Slovak Republic\": \"\",  # Change this to the correct ISO name\n",
    "}\n",
    "\n",
    "# Manually update the mapping dictionary with the correct ISO names\n",
    "name_mapping[\"Micronesia, Fed. Sts.\"] = \"Micronesia, Federated States of\"\n",
    "name_mapping[\"Lao PDR\"] = \"Lao People's Democratic Republic\"\n",
    "name_mapping[\"Iran, Islamic Rep.\"] = \"Iran, Islamic Republic of\"\n",
    "name_mapping[\"Korea, Dem. People's Rep.\"] = \"Korea, Democratic People's Republic of\"\n",
    "name_mapping[\"Kyrgyz Republic\"] = \"Kyrgyzstan\"\n",
    "name_mapping[\"St. Lucia\"] = \"Saint Lucia\"\n",
    "name_mapping[\"Slovak Republic\"] = \"Slovakia\"\n",
    "\n",
    "# Apply name mapping to GDP dataset\n",
    "gdp_df['Country Name'] = gdp_df['Country Name'].map(name_mapping).fillna(gdp_df['Country Name'])\n",
    "\n",
    "gdp_countries = gdp_df['Country Name'].unique()\n",
    "iso_countries = iso_df['Name'].unique()\n",
    "\n",
    "# Check if the same stateid is used for each country in both datasets\n",
    "consistent_stateids = True\n",
    "inconsistent_countries = []\n",
    "\n",
    "for country in gdp_countries:\n",
    "    if country in iso_countries:\n",
    "        gdp_stateid = gdp_df.loc[gdp_df['Country Name'] == country, 'stateid'].iloc[0]\n",
    "        iso_stateid = iso_df.loc[iso_df['Name'] == country, 'stateid'].iloc[0]\n",
    "        \n",
    "        if gdp_stateid != iso_stateid:\n",
    "            consistent_stateids = False\n",
    "            inconsistent_countries.append(country)\n",
    "\n",
    "if consistent_stateids:\n",
    "    print(\"The same stateid is used for each country in both datasets.\")\n",
    "else:\n",
    "    print(\"The stateids are not consistent for the following countries:\")\n",
    "    print(inconsistent_countries)\n",
    "\n",
    "# No data available for North Korea; estimation from tradingeconomics.com + linear interpolation\n",
    "\n",
    "nk_gdp = {\n",
    "    1989: 15770000000,\n",
    "    1990: None,\n",
    "    1991: None,\n",
    "    1992: 11000000000,\n",
    "    1993: None,\n",
    "    1994: None,\n",
    "    1995: 4850000000,\n",
    "    1996: None,\n",
    "    1997: None,\n",
    "    1998: 11000000000,\n",
    "    1999: None,\n",
    "    2000: None,\n",
    "    2001: None,\n",
    "    2002: None,\n",
    "    2003: None,\n",
    "    2004: None,\n",
    "    2005: None,\n",
    "    2006: None,\n",
    "    2007: None,\n",
    "    2008: None,\n",
    "    2009: None,\n",
    "    2010: None,\n",
    "    2011: None,\n",
    "    2012: None,\n",
    "    2013: None,\n",
    "    2014: None,\n",
    "    2015: None,\n",
    "    2016: None,\n",
    "    2017: None,\n",
    "    2018: None,\n",
    "    2019: None,\n",
    "    2020: None,\n",
    "    2021: None,\n",
    "    2022: 20000000000\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "nk_gdp_df = pd.DataFrame.from_dict(nk_gdp, orient='index', columns=['GDP'])\n",
    "\n",
    "# Convert index to a column\n",
    "nk_gdp_df.reset_index(inplace=True)\n",
    "nk_gdp_df.rename(columns={'index': 'Year'}, inplace=True)\n",
    "\n",
    "# Interpolate missing values linearly\n",
    "nk_gdp_df['GDP'] = nk_gdp_df['GDP'].interpolate()\n",
    "\n",
    "# Provided data\n",
    "nk_gdp_values = {\n",
    "    1989: 1.577000e+10, 1990: 1.418000e+10, 1991: 1.259000e+10, 1992: 1.100000e+10, 1993: 8.950000e+09,\n",
    "    1994: 6.900000e+09, 1995: 4.850000e+09, 1996: 6.900000e+09, 1997: 8.950000e+09, 1998: 1.100000e+10,\n",
    "    1999: 1.137500e+10, 2000: 1.175000e+10, 2001: 1.212500e+10, 2002: 1.250000e+10, 2003: 1.287500e+10,\n",
    "    2004: 1.325000e+10, 2005: 1.362500e+10, 2006: 1.400000e+10, 2007: 1.437500e+10, 2008: 1.475000e+10,\n",
    "    2009: 1.512500e+10, 2010: 1.550000e+10, 2011: 1.587500e+10, 2012: 1.625000e+10, 2013: 1.662500e+10,\n",
    "    2014: 1.700000e+10, 2015: 1.737500e+10, 2016: 1.775000e+10, 2017: 1.812500e+10, 2018: 1.850000e+10,\n",
    "    2019: 1.887500e+10, 2020: 1.925000e+10, 2021: 1.962500e+10, 2022: 2.000000e+10\n",
    "}\n",
    "\n",
    "# Locate the row with stateid equal to \"PRK\" in gdp_df\n",
    "prk_row_index = gdp_df.index[gdp_df['stateid'] == 'PRK'].tolist()[0]\n",
    "\n",
    "# Replace the values in columns 1989 to 2022 with the provided values\n",
    "for year, gdp_value in nk_gdp_values.items():\n",
    "    gdp_df.at[prk_row_index, str(year)] = gdp_value\n",
    "\n",
    "\n",
    "# No data for Virgin Islands and Gibraltar: drop the columns (not used in main_df)\n",
    "gdp_df = gdp_df[~gdp_df['stateid'].isin(['VGB', 'GIB'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f1c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting from zip file\n",
    "zip_file_path = \"Data/EdStats_CSV.zip\"\n",
    "\n",
    "csv_file_name = 'EdStatsData.csv'\n",
    "\n",
    "# Open the .zip archive\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract the CSV file from the .zip archive\n",
    "    with zip_ref.open(csv_file_name) as csv_file:\n",
    "        # Read the CSV file using pandas\n",
    "        education_df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "# Only keep the countries in the recognized_country_codes list\n",
    "education_df = education_df[education_df[\"Country Code\"].isin(recognized_country_codes)]\n",
    "\n",
    "# Only keep relevant columns, between 1989 and 2022\n",
    "education_df = education_df[[\"Country Name\", \"Country Code\", \"Indicator Name\" ,\"Indicator Code\", \"1989\", \"1990\", \"1991\", \"1992\", \"1993\", \"1994\", \"1995\",\n",
    "                             \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\",\n",
    "                             \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\"]]\n",
    "\n",
    "# Delete rows where every year is NaN\n",
    "education_df = education_df.dropna(how='all', subset=[\"1989\", \"1990\", \"1991\", \"1992\", \"1993\", \"1994\", \"1995\",\n",
    "                                                      \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\",\n",
    "                                                      \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\",\n",
    "                                                      \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\"])\n",
    "\n",
    "\n",
    "# Drop all rows where indicator name = Population growth (annual %)\n",
    "education_df = education_df[education_df[\"Indicator Name\"] != \"Population growth (annual %)\"]\n",
    "\n",
    "\n",
    "# Drop all columns where more than 35% of the values are NaN\n",
    "education_df = education_df.dropna(thresh=0.35*len(education_df), axis=1)\n",
    "\n",
    "# Drop 2003, 2006, 2007, 2008, 2009, 2011, 2012, 2013, 2015\n",
    "education_df = education_df.drop(columns=[\"2003\", \"2006\", \"2007\", \"2008\", \"2009\", \"2011\", \"2012\", \"2013\", \"2015\"])\n",
    "\n",
    "# Drop rows where the value for 1995, 2000, 2005 and 2010 is NaN\n",
    "education_df = education_df.dropna(subset=[\"1995\", \"2000\", \"2005\", \"2010\"], how='all')\n",
    "\n",
    "# Drop the rows where 2 or more value for 1995, 2000, 2005 and 2010 are NaN\n",
    "education_df = education_df.dropna(subset=[\"1995\", \"2000\", \"2005\", \"2010\"], thresh=2)\n",
    "\n",
    "# Pivot the dataframe\n",
    "education_df = education_df.pivot_table(index=['Country Name', 'Country Code'], columns='Indicator Name', values=['1995', '2000', '2005', '2010'])\n",
    "\n",
    "# Reset index to make 'Country Name' and 'Country Code' regular columns\n",
    "education_df.reset_index(inplace=True)\n",
    "\n",
    "# Flatten column names\n",
    "education_df.columns = [' '.join(col).strip() for col in education_df.columns.values]\n",
    "\n",
    "# Drop columns where more than 20% of the values are NaN\n",
    "education_df = education_df.dropna(thresh=0.5*len(education_df), axis=1)\n",
    "\n",
    "# Drop all columns that contain the word \"total\"\n",
    "education_df = education_df[education_df.columns.drop(list(education_df.filter(like='Total')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c53e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586a6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the main_df\n",
    "\n",
    "# Remove columns with disagregated deaths. Only keep \"prior\" information and cumulative total deaths.\n",
    "main_df = main_df.loc[:, ['country_id_cy', 'country_cy', 'year_cy', 'region_cy', 'sb_dyad_count_cy', 'sb_dyad_ids_cy',\n",
    "                          'sb_intrastate_dyad_count_cy', 'sb_intrastate_main_govt_inv_incomp_cy',\n",
    "                          'sb_interstate_dyad_count_cy',\n",
    "                          'sb_interstate_main_govt_inv_incomp_cy', 'ns_dyad_count_cy', 'ns_dyad_ids_cy',\n",
    "                          'os_dyad_count_cy', 'os_dyad_ids_cy', 'os_main_govt_inv_cy', 'os_any_govt_inv_cy',\n",
    "                          'os_nsgroup_inv_cy', 'cumulative_total_deaths_parties_in_orgvio_cy',\n",
    "                          'cumulative_total_deaths_civilians_in_orgvio_cy', 'cumulative_total_deaths_unknown_in_orgvio_cy',\n",
    "                          'cumulative_total_deaths_in_orgvio_best_cy']]\n",
    "\n",
    "# Importing battle_death data set, to get the dyads \n",
    "\n",
    "# importing battle_death dataset\n",
    "battle_death_df = pd.read_csv(\"Data/battle_deaths.csv\")\n",
    "\n",
    "\n",
    "# Function to get incompatibility value from battle_death_df based on dyad_id\n",
    "def get_incompatibility(dyad_ids):\n",
    "    # Initialize a list to store incompatibility values for each dyad_id\n",
    "    incompatibilities = []\n",
    "    \n",
    "    # Split the dyad_ids separated by \";\"\n",
    "    dyad_ids = dyad_ids.split(\";\")\n",
    "    \n",
    "    # Iterate over each dyad_id\n",
    "    for dyad_id in dyad_ids:\n",
    "        # Check if dyad_id is 'NO_DYAD'\n",
    "        if dyad_id != 'NO_DYAD':\n",
    "            # Look up the incompatibility value from battle_death_df\n",
    "            incompatibility = battle_death_df.loc[battle_death_df['dyad_id'] == int(dyad_id), 'incompatibility'].values\n",
    "            # If the dyad_id is found, append the incompatibility value to the list\n",
    "            if len(incompatibility) > 0:\n",
    "                incompatibilities.extend(incompatibility)\n",
    "    \n",
    "    # Return the maximum incompatibility value found for the dyad_ids\n",
    "    return max(incompatibilities) if incompatibilities else None\n",
    "\n",
    "# Create a new column 'incompatibility' in main_df using the function\n",
    "main_df['incompatibility'] = main_df['sb_dyad_ids_cy'].apply(get_incompatibility)\n",
    "\n",
    "main_df.insert(main_df.columns.get_loc('sb_dyad_ids_cy') + 1, 'incompatibility', main_df.pop('incompatibility'))\n",
    "\n",
    "# Replace NaN values from 'incompatibility' column with 0 (= no state incompatibility)\n",
    "main_df['incompatibility'] = main_df['incompatibility'].fillna(0)\n",
    "\n",
    "# Change Incompatibility values to integers\n",
    "main_df['incompatibility'] = main_df['incompatibility'].astype(int)\n",
    "\n",
    "#####################################################\n",
    "non_state = pd.read_csv(\"Data/Nonstate_v23_1.csv\")\n",
    "\n",
    "# Convert 'dyad_id' column in 'non_state' DataFrame to string type\n",
    "non_state['dyad_id'] = non_state['dyad_id'].astype(str)\n",
    "\n",
    "# Explode the 'ns_dyad_ids_cy' column to create multiple rows for each id\n",
    "exploded_df = main_df.explode('ns_dyad_ids_cy')\n",
    "\n",
    "# Merge with 'non_state' DataFrame on 'dyad_id'\n",
    "merged_df = exploded_df.merge(non_state, how='left', left_on='ns_dyad_ids_cy', right_on='dyad_id')\n",
    "\n",
    "# Convert 'org' column to string type\n",
    "merged_df['org'] = merged_df['org'].astype(str)\n",
    "\n",
    "# Group by the original index and aggregate the 'org' values\n",
    "grouped_df = merged_df.groupby(merged_df.index)['org'].apply(lambda x: ';'.join(x)).reset_index()\n",
    "\n",
    "# Merge the aggregated 'org' values back to 'main_df'\n",
    "main_df = main_df.merge(grouped_df, how='left', left_index=True, right_on='index')\n",
    "\n",
    "# Drop unnecessary columns except 'ns_dyad_ids_cy'\n",
    "main_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Rename the merged column to 'org'\n",
    "main_df.rename(columns={'org_x': 'org'}, inplace=True)\n",
    "\n",
    "# Replace \"nan\" with 0 in 'org' column\n",
    "main_df['org'] = main_df['org'].replace('nan', 0)\n",
    "\n",
    "# Drop columns: sb_instrastate_dyad_count, sb_interstate_dyad_count\n",
    "main_df = main_df.drop(columns=['sb_intrastate_dyad_count_cy', 'sb_interstate_dyad_count_cy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5283451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_unique_names = education_df['Country Name'].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "\n",
    "# Import unique country names from main_df\n",
    "comparison_df['Country Name (Main)'] = main_df['country_cy'].unique()\n",
    "comparison_df['Country Name (Main)'] = sorted(comparison_df['Country Name (Main)'])\n",
    "\n",
    "# Import unique country names from gdp_df\n",
    "gdp_unique_names = gdp_df['Country Name'].drop_duplicates().reset_index(drop=True)\n",
    "comparison_df['Country Name (GDP)'] = gdp_unique_names\n",
    "comparison_df['Country Name (GDP)'] = sorted(comparison_df['Country Name (GDP)'])\n",
    "\n",
    "# Determine the maximum length among the unique country name lists\n",
    "max_length = max(len(comparison_df), len(education_unique_names))\n",
    "\n",
    "# Extend the length of comparison_df if necessary\n",
    "if max_length > len(comparison_df):\n",
    "    comparison_df = comparison_df.reindex(range(max_length))\n",
    "\n",
    "# Import unique country names from education_df\n",
    "comparison_df['Country Name (Education)'] = education_unique_names[:max_length]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbce02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store perfect matches\n",
    "perfect_matches = []\n",
    "\n",
    "# Iterate through each country name in the \"Country Name (Main)\" column\n",
    "for main_country in comparison_df['Country Name (Main)']:\n",
    "    # Look for a perfect match in the \"Country Name (GDP)\" column\n",
    "    gdp_match = comparison_df[comparison_df['Country Name (GDP)'] == main_country]\n",
    "    \n",
    "    # Look for a perfect match in the \"Country Name (Education)\" column\n",
    "    edu_match = comparison_df[comparison_df['Country Name (Education)'] == main_country]\n",
    "    \n",
    "    # Check if perfect match is found in both GDP and Education columns\n",
    "    if not gdp_match.empty and not edu_match.empty:\n",
    "        # Take the first match from each DataFrame\n",
    "        gdp_country = gdp_match.iloc[0]['Country Name (GDP)']\n",
    "        edu_country = edu_match.iloc[0]['Country Name (Education)']\n",
    "        \n",
    "        # Append the perfect match to the list\n",
    "        perfect_matches.append({'Country Name (Main)': main_country,\n",
    "                                'Country Name (GDP)': gdp_country,\n",
    "                                'Country Name (Education)': edu_country})\n",
    "\n",
    "# Convert the list of perfect matches to a DataFrame\n",
    "tinder_df = pd.DataFrame(perfect_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d5dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a threshold for similarity score\n",
    "threshold = 70  # You can adjust this value based on your preference\n",
    "\n",
    "# Initialize an empty list to store potential matches\n",
    "potential_matches = []\n",
    "\n",
    "# Iterate through each country name in the \"Country Name (Main)\" column\n",
    "for main_country in comparison_df['Country Name (Main)']:\n",
    "    # Check if the country name is not NaN\n",
    "    if pd.notna(main_country):\n",
    "        # Calculate similarity scores with each value in the \"Country Name (GDP)\" column\n",
    "        gdp_scores = process.extract(main_country, comparison_df['Country Name (GDP)'], scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        # Calculate similarity scores with each value in the \"Country Name (Education)\" column\n",
    "        edu_scores = process.extract(main_country, comparison_df['Country Name (Education)'], scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        # Get the highest similarity score for GDP and Education columns\n",
    "        max_gdp_score = max(gdp_scores, key=lambda x: x[1])[1]\n",
    "        max_edu_score = max(edu_scores, key=lambda x: x[1])[1]\n",
    "        \n",
    "        # Check if the highest similarity score is above the threshold\n",
    "        if max_gdp_score >= threshold or max_edu_score >= threshold:\n",
    "            # Get the matched country name with the highest similarity score\n",
    "            matched_gdp = gdp_scores[0][0] if max_gdp_score >= threshold else None\n",
    "            matched_edu = edu_scores[0][0] if max_edu_score >= threshold else None\n",
    "            \n",
    "            # Append the potential match to the list\n",
    "            potential_matches.append({'Country Name (Main)': main_country,\n",
    "                                      'Country Name (GDP)': matched_gdp,\n",
    "                                      'Country Name (Education)': matched_edu})\n",
    "\n",
    "# Convert the list of potential matches to a DataFrame\n",
    "potential_matches_df = pd.DataFrame(potential_matches)\n",
    "\n",
    "# Filter potential_matches_df to display only non-perfect matches\n",
    "non_perfect_matches_df = potential_matches_df[(potential_matches_df['Country Name (GDP)'] != potential_matches_df['Country Name (Main)']) \n",
    "                                              | (potential_matches_df['Country Name (Education)'] != potential_matches_df['Country Name (Main)'])]\n",
    "\n",
    "\n",
    "# Convert perfect_matches list to DataFrame\n",
    "perfect_matches_df = pd.DataFrame(perfect_matches)\n",
    "\n",
    "# Keep the perfect matches from before\n",
    "tinder_df = pd.concat([tinder_df, perfect_matches_df], ignore_index=True)\n",
    "\n",
    "# Define the corrected matches\n",
    "corrected_matches = [\n",
    "    {\"Main\": \"Bolivia\", \"GDP\": \"Bolivia, Plurinational State of\", \"Education\": \"Bolivia\"},\n",
    "    {\"Main\": \"Brunei\", \"GDP\": \"Burundi\", \"Education\": \"Burundi\"},\n",
    "    {\"Main\": \"Czech Republic\", \"GDP\": \"Czechia\", \"Education\": \"Czech Republic\"},\n",
    "    {\"Main\": \"Czechoslovakia\", \"GDP\": \"Czechia\", \"Education\": \"Czech Republic\"},\n",
    "    {\"Main\": \"DR Congo (Zaire)\", \"GDP\": \"Congo\", \"Education\": \"Congo, Dem. Rep.\"},\n",
    "    {\"Main\": \"Egypt\", \"GDP\": \"Egypt\", \"Education\": \"Egypt, Arab Rep.\"},\n",
    "    {\"Main\": \"Gambia\", \"GDP\": \"Gambia\", \"Education\": \"Gambia, The\"},\n",
    "    {\"Main\": \"German Democratic Republic\", \"GDP\": \"Germany\", \"Education\": \"Germany\"},\n",
    "    {\"Main\": \"Iran\", \"GDP\": \"Iran, Islamic Republic of\", \"Education\": \"Iran, Islamic Rep.\"},\n",
    "    {\"Main\": \"Kyrgyzstan\", \"GDP\": \"Kyrgyzstan\", \"Education\": \"Kyrgyz Republic\"},\n",
    "    {\"Main\": \"Moldova\", \"GDP\": \"Moldova, Republic of\", \"Education\": \"Moldova\"},\n",
    "    {\"Main\": \"North Korea\", \"GDP\": \"Korea, Democratic People's Republic of\", \"Education\": \"Korea, Dem. People’s Rep.\"},\n",
    "    {\"Main\": \"North Macedonia\", \"GDP\": \"North Macedonia\", \"Education\": \"Macedonia, FYR\"},\n",
    "    {\"Main\": \"Saint Vincent and the Grenadines\", \"GDP\": \"Saint Vincent and the Grenadines\", \"Education\": \"St. Vincent and the Grenadines\"},\n",
    "    {\"Main\": \"Slovakia\", \"GDP\": \"Slovakia\", \"Education\": \"Slovak Republic\"},\n",
    "    {\"Main\": \"South Africa\", \"GDP\": \"South Africa\", \"Education\": \"South Africa\"},\n",
    "    {\"Main\": \"South Korea\", \"GDP\": \"Korea, Republic of\", \"Education\": \"Korea, Rep.\"},\n",
    "    {\"Main\": \"Syria\", \"GDP\": \"Syrian Arab Republic\", \"Education\": \"Serbia\"},\n",
    "    {\"Main\": \"Taiwan\", \"GDP\": \"Brunei Darussalam\", \"Education\": \"Brunei Darussalam\"},\n",
    "    {\"Main\": \"Tanzania\", \"GDP\": \"Tanzania, United Republic of\", \"Education\": \"Tanzania\"},\n",
    "    {\"Main\": \"Turkey\", \"GDP\": \"Türkiye\", \"Education\": \"Turkey\"},\n",
    "    {\"Main\": \"United States of America\", \"GDP\": \"United States\", \"Education\": \"United States\"},\n",
    "    {\"Main\": \"Uzbekistan\", \"GDP\": \"Uzbekistan\", \"Education\": \"Uzbekistan\"},\n",
    "    {\"Main\": \"Vanuatu\", \"GDP\": \"Vanuatu\", \"Education\": \"Vanuatu\"},\n",
    "    {\"Main\": \"Venezuela\", \"GDP\": \"Venezuela, RB\", \"Education\": \"Venezuela, RB\"},\n",
    "    {\"Main\": \"Zambia\", \"GDP\": \"Gambia\", \"Education\": \"Zambia\"}\n",
    "]\n",
    "\n",
    "# Append the corrected matches to tinder_df\n",
    "tinder_df = pd.concat([tinder_df, pd.DataFrame(corrected_matches)], ignore_index=True)\n",
    "\n",
    "# Correct the values in the last 3 columns, moving them to the first 3 columns\n",
    "for index in range(292, len(tinder_df)):\n",
    "    main_value = tinder_df.loc[index, 'Main']\n",
    "    gdp_value = tinder_df.loc[index, 'GDP']\n",
    "    education_value = tinder_df.loc[index, 'Education']\n",
    "    \n",
    "    # Move the values to the first 3 columns\n",
    "    tinder_df.loc[index, 'Country Name (Main)'] = main_value\n",
    "    tinder_df.loc[index, 'Country Name (GDP)'] = gdp_value\n",
    "    tinder_df.loc[index, 'Country Name (Education)'] = education_value\n",
    "\n",
    "# Drop the 'Main', 'GDP', and 'Education' columns\n",
    "tinder_df.drop(columns=['Main', 'GDP', 'Education'], inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "tinder_df.dropna(inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "tinder_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "tinder_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# List of all country names in main_df\n",
    "all_countries_main_df = main_df['country_cy'].tolist()\n",
    "\n",
    "# List of country names in tinder_df\n",
    "country_names_tinder_df = tinder_df['Country Name (Main)'].tolist()\n",
    "\n",
    "# Find the ignored countries (those in main_df but not in tinder_df)\n",
    "ignored_countries = set(all_countries_main_df) - set(country_names_tinder_df)\n",
    "\n",
    "# Create a DataFrame for unique ignored countries\n",
    "ignored_countries_df = pd.DataFrame({'Ignored Country Name': list(ignored_countries)})\n",
    "\n",
    "# Manually match the ignored country names with potential matches from GDP and Education datasets\n",
    "matches = [\n",
    "    {\"Ignored Country Name\": \"Algeria\", \"Matched Country Name (GDP)\": \"Algeria\", \"Matched Country Name (Education)\": \"Algeria\"},\n",
    "    {\"Ignored Country Name\": \"Zimbabwe (Rhodesia)\", \"Matched Country Name (GDP)\": \"Zimbabwe\", \"Matched Country Name (Education)\": \"Zimbabwe\"},\n",
    "    {\"Ignored Country Name\": \"Vatican City State\", \"Matched Country Name (GDP)\": \"N/A\", \"Matched Country Name (Education)\": \"N/A\"},\n",
    "    {\"Ignored Country Name\": \"Kingdom of eSwatini (Swaziland)\", \"Matched Country Name (GDP)\": \"Eswatini\", \"Matched Country Name (Education)\": \"Swaziland\"},\n",
    "    {\"Ignored Country Name\": \"Cambodia (Kampuchea)\", \"Matched Country Name (GDP)\": \"Cambodia\", \"Matched Country Name (Education)\": \"Cambodia\"},\n",
    "    {\"Ignored Country Name\": \"Vietnam (North Vietnam)\", \"Matched Country Name (GDP)\": \"Vietnam\", \"Matched Country Name (Education)\": \"Vietnam\"},\n",
    "    {\"Ignored Country Name\": \"Bosnia-Herzegovina\", \"Matched Country Name (GDP)\": \"Bosnia and Herzegovina\", \"Matched Country Name (Education)\": \"Bosnia and Herzegovina\"},\n",
    "    {\"Ignored Country Name\": \"Albania\", \"Matched Country Name (GDP)\": \"Albania\", \"Matched Country Name (Education)\": \"Albania\"},\n",
    "    {\"Ignored Country Name\": \"Congo\", \"Matched Country Name (GDP)\": \"Congo, Rep.\", \"Matched Country Name (Education)\": \"Congo, Dem. Rep.\"},\n",
    "    {\"Ignored Country Name\": \"East Timor\", \"Matched Country Name (GDP)\": \"Timor-Leste\", \"Matched Country Name (Education)\": \"Timor-Leste\"},\n",
    "    {\"Ignored Country Name\": \"Antigua & Barbuda\", \"Matched Country Name (GDP)\": \"Antigua and Barbuda\", \"Matched Country Name (Education)\": \"Antigua and Barbuda\"},\n",
    "    {\"Ignored Country Name\": \"Laos\", \"Matched Country Name (GDP)\": \"Lao PDR\", \"Matched Country Name (Education)\": \"Lao PDR\"},\n",
    "    {\"Ignored Country Name\": \"Ivory Coast\", \"Matched Country Name (GDP)\": \"Cote d'Ivoire\", \"Matched Country Name (Education)\": \"Cote d'Ivoire\"},\n",
    "    {\"Ignored Country Name\": \"Federated States of Micronesia\", \"Matched Country Name (GDP)\": \"Micronesia, Fed. Sts.\", \"Matched Country Name (Education)\": \"Micronesia, Fed. Sts.\"},\n",
    "    {\"Ignored Country Name\": \"Madagascar (Malagasy)\", \"Matched Country Name (GDP)\": \"Madagascar\", \"Matched Country Name (Education)\": \"Madagascar\"},\n",
    "    {\"Ignored Country Name\": \"Afghanistan\", \"Matched Country Name (GDP)\": \"Afghanistan\", \"Matched Country Name (Education)\": \"Afghanistan\"},\n",
    "    {\"Ignored Country Name\": \"Kosovo\", \"Matched Country Name (GDP)\": \"N/A\", \"Matched Country Name (Education)\": \"Kosovo\"},\n",
    "    {\"Ignored Country Name\": \"Russia (Soviet Union)\", \"Matched Country Name (GDP)\": \"Russian Federation\", \"Matched Country Name (Education)\": \"Russian Federation\"},\n",
    "    {\"Ignored Country Name\": \"Yemen (South Yemen)\", \"Matched Country Name (GDP)\": \"Yemen, Rep.\", \"Matched Country Name (Education)\": \"Yemen, Rep.\"},\n",
    "    {\"Ignored Country Name\": \"Saint Kitts and Nevis\", \"Matched Country Name (GDP)\": \"St. Kitts and Nevis\", \"Matched Country Name (Education)\": \"St. Kitts and Nevis\"},\n",
    "    {\"Ignored Country Name\": \"Bahamas\", \"Matched Country Name (GDP)\": \"Bahamas, The\", \"Matched Country Name (Education)\": \"Bahamas, The\"},\n",
    "    {\"Ignored Country Name\": \"Cape Verde\", \"Matched Country Name (GDP)\": \"Cabo Verde\", \"Matched Country Name (Education)\": \"Cabo Verde\"},\n",
    "    {\"Ignored Country Name\": \"Saint Lucia\", \"Matched Country Name (GDP)\": \"St. Lucia\", \"Matched Country Name (Education)\": \"St. Lucia\"},\n",
    "    {\"Ignored Country Name\": \"Myanmar (Burma)\", \"Matched Country Name (GDP)\": \"Myanmar\", \"Matched Country Name (Education)\": \"Myanmar\"},\n",
    "    {\"Ignored Country Name\": \"Serbia (Yugoslavia)\", \"Matched Country Name (GDP)\": \"Serbia\", \"Matched Country Name (Education)\": \"Serbia\"},\n",
    "    {\"Ignored Country Name\": \"Samoa/Western Samoa\", \"Matched Country Name (GDP)\": \"Samoa\", \"Matched Country Name (Education)\": \"Samoa\"},\n",
    "    {\"Ignored Country Name\": \"Yemen (North Yemen)\", \"Matched Country Name (GDP)\": \"N/A\", \"Matched Country Name (Education)\": \"Yemen, Rep.\"}\n",
    "]\n",
    "\n",
    "# Create DataFrame from the manually matched data\n",
    "matched_df = pd.DataFrame(matches)\n",
    "\n",
    "# 1. Add a duplicate row of Tuvalu and name it \"Vatican City State\" in gdp_df\n",
    "vatican_row_gdp = gdp_df[gdp_df['Country Name'] == 'Tuvalu'].copy()\n",
    "vatican_row_gdp['Country Name'] = 'Vatican City State'\n",
    "gdp_df = pd.concat([gdp_df, vatican_row_gdp], ignore_index=True)\n",
    "\n",
    "# 1. Add a duplicate row of Tuvalu and name it \"Vatican City State\" in education_df\n",
    "vatican_row_education = education_df[education_df['Country Name'] == 'Tuvalu'].copy()\n",
    "vatican_row_education['Country Name'] = 'Vatican City State'\n",
    "education_df = pd.concat([education_df, vatican_row_education], ignore_index=True)\n",
    "\n",
    "# 2. Add a duplicate row of Malawi and name it \"Kosovo\" in gdp_df\n",
    "kosovo_row_gdp = gdp_df[gdp_df['Country Name'] == 'Malawi'].copy()\n",
    "kosovo_row_gdp['Country Name'] = 'Kosovo'\n",
    "gdp_df = pd.concat([gdp_df, kosovo_row_gdp], ignore_index=True)\n",
    "\n",
    "# Replace \"N/A\" with \"Tuvalu\" for \"Vatican City State\" row\n",
    "matched_df.loc[matched_df['Ignored Country Name'] == 'Vatican City State', 'Matched Country Name (GDP)'] = 'Tuvalu'\n",
    "matched_df.loc[matched_df['Ignored Country Name'] == 'Vatican City State', 'Matched Country Name (Education)'] = 'Tuvalu'\n",
    "\n",
    "# Replace \"Malawi\" in \"Matched Country Name (GDP)\" for \"Kosovo\" row\n",
    "matched_df.loc[matched_df['Ignored Country Name'] == 'Kosovo', 'Matched Country Name (GDP)'] = 'Malawi'\n",
    "\n",
    "matched_df.loc[matched_df['Ignored Country Name'] == 'Yemen (North Yemen)', 'Matched Country Name (GDP)'] = 'Yemen'\n",
    "\n",
    "# Create a new DataFrame\n",
    "countries_df = pd.DataFrame()\n",
    "\n",
    "# Concatenate the first column of each dataset into the first column of countries_df\n",
    "countries_df['Country Name'] = pd.concat([perfect_matches_df.iloc[:, 0], tinder_df.iloc[:, 0], matched_df.iloc[:, 0]], ignore_index=True)\n",
    "\n",
    "countries_df.rename(columns={'Country Name': 'main_name'}, inplace=True)\n",
    "\n",
    "# Drop duplicates in the \"main_name\" column of countries_df\n",
    "countries_df.drop_duplicates(subset='main_name', inplace=True)\n",
    "\n",
    "# Rename the \"Country Name (Main)\" column in perfect_matches_df\n",
    "perfect_matches_df.rename(columns={'Country Name (Main)': 'main_name'}, inplace=True)\n",
    "\n",
    "for index, row in countries_df.iterrows():\n",
    "    main_name = row['main_name']\n",
    "    \n",
    "    # Check if the main_name exists in tinder_df\n",
    "    if main_name in tinder_df['Country Name (Main)'].values:\n",
    "        # Get the corresponding GDP value from tinder_df and update gdp_name\n",
    "        gdp_value = tinder_df.loc[tinder_df['Country Name (Main)'] == main_name, 'Country Name (GDP)'].iloc[0]\n",
    "        countries_df.at[index, 'gdp_name'] = gdp_value\n",
    "    elif main_name in matched_df['Ignored Country Name'].values:\n",
    "        # If not found in tinder_df, check in matched_df and update gdp_name accordingly\n",
    "        gdp_value = matched_df.loc[matched_df['Ignored Country Name'] == main_name, 'Matched Country Name (GDP)'].iloc[0]\n",
    "        countries_df.at[index, 'gdp_name'] = gdp_value\n",
    "    else:\n",
    "        # Handle the case where neither tinder_df nor matched_df contains the main_name\n",
    "        countries_df.at[index, 'gdp_name'] = None\n",
    "\n",
    "# Update \"education_name\" column with values from perfect_matches_df where available\n",
    "countries_df = pd.merge(countries_df, perfect_matches_df[['main_name', 'Country Name (Education)']],\n",
    "                        left_on='main_name', right_on='main_name', how='left')\n",
    "countries_df.rename(columns={'Country Name (Education)': 'education_name'}, inplace=True)\n",
    "\n",
    "for index, row in countries_df.iterrows():\n",
    "    main_name = row['main_name']\n",
    "    # Check if the main_name exists in tinder_df\n",
    "    if main_name in tinder_df['Country Name (Main)'].values:\n",
    "        education_value = tinder_df.loc[tinder_df['Country Name (Main)'] == main_name, 'Country Name (Education)'].iloc[0]\n",
    "        countries_df.at[index, 'education_name'] = education_value\n",
    "    else:\n",
    "        # Check if the main_name exists in matched_df\n",
    "        if main_name in matched_df['Ignored Country Name'].values:\n",
    "            education_value = matched_df.loc[matched_df['Ignored Country Name'] == main_name, 'Matched Country Name (Education)'].iloc[0]\n",
    "            countries_df.at[index, 'education_name'] = education_value\n",
    "\n",
    "# Iterate through each row in gdp_df\n",
    "for index, row in gdp_df.iterrows():\n",
    "    country_name_gdp = row['Country Name']\n",
    "    \n",
    "    # Check if the country name in gdp_df matches any entry in countries_df['gdp_name']\n",
    "    matched_row = countries_df[countries_df['gdp_name'] == country_name_gdp]\n",
    "    \n",
    "    # If a match is found, update the country name in gdp_df\n",
    "    if not matched_row.empty:\n",
    "        new_country_name = matched_row.iloc[0]['gdp_name']\n",
    "        gdp_df.at[index, 'Country Name'] = new_country_name\n",
    "    else:\n",
    "        # If no match is found, drop the row from gdp_df\n",
    "        gdp_df.drop(index, inplace=True)\n",
    "\n",
    "# Reset the index of gdp_df after dropping rows\n",
    "gdp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Iterate through each row in education_df\n",
    "for index, row in education_df.iterrows():\n",
    "    country_name_education = row['Country Name']\n",
    "    \n",
    "    # Check if the country name in education_df matches any entry in countries_df['education_name']\n",
    "    matched_row = countries_df[countries_df['education_name'] == country_name_education]\n",
    "    \n",
    "    # If a match is found, update the country name in education_df\n",
    "    if not matched_row.empty:\n",
    "        new_country_name = matched_row.iloc[0]['education_name']\n",
    "        education_df.at[index, 'Country Name'] = new_country_name\n",
    "    else:\n",
    "        # If no match is found, drop the row from education_df\n",
    "        education_df.drop(index, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea02d353",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Step 1: Impute Missing Values\n",
    "# Exclude non-numeric columns from imputation\n",
    "numeric_cols = education_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputed_data = imputer.fit_transform(education_df[numeric_cols])\n",
    "\n",
    "# Convert the imputed array back to DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "\n",
    "# Step 2: Scale the Data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(imputed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd50ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a44fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63511a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237fc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe873a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199697e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae01b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f9371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914ae10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089ea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54616d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe59a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0fb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519539f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2c608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de993a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44d16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6d029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
